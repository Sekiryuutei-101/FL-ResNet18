{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5160613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "#!pip install -U flwr[\"simulation\"]\n",
    "#!pip install numpy pandas pillow scikit-learn matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1445d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flwr torch torchvision torchaudio tqdm pillow pandas numpy matplotlib seaborn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f379a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pytorch run in terminal\n",
    "pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu130\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4214ac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Installing packages for Federated Learning project...\n",
      "This may take a few minutes...\n",
      "\n",
      "Installing flwr[simulation]...\n",
      "Installing numpy...\n",
      "Installing pandas...\n",
      "Installing pillow...\n",
      "Installing scikit-learn...\n",
      "Installing matplotlib...\n",
      "Installing tqdm...\n",
      "Installing seaborn...\n",
      "Installing flwr[simulation]...\n",
      "\n",
      "‚úÖ All packages installed successfully!\n",
      "‚ö†Ô∏è  IMPORTANT: Please restart the Jupyter kernel:\n",
      "   Kernel ‚Üí Restart Kernel\n",
      "   Then skip this cell and continue with Cell 2\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Installation (Run this once)\n",
    "# This installs all necessary packages for the federated learning project\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install all required packages for the project\"\"\"\n",
    "    \n",
    "    packages = [\n",
    "        #\"torch\",\n",
    "        #\"torchvision\", \n",
    "        #\"torchaudio\",\n",
    "        \"flwr[simulation]\",\n",
    "        #\"ray[rllib]\",\n",
    "        \"numpy\",\n",
    "        \"pandas\",\n",
    "        \"pillow\",\n",
    "        \"scikit-learn\",\n",
    "        \"matplotlib\",\n",
    "        \"tqdm\",\n",
    "        \"seaborn\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üì¶ Installing packages for Federated Learning project...\")\n",
    "    print(\"This may take a few minutes...\\n\")\n",
    "    \n",
    "    for package in packages:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"-q\"])\n",
    "    \n",
    "    # Install flwr with simulation support\n",
    "    print(\"Installing flwr[simulation]...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"flwr[simulation]\", \"-q\"])\n",
    "    \n",
    "    print(\"\\n‚úÖ All packages installed successfully!\")\n",
    "    print(\"‚ö†Ô∏è  IMPORTANT: Please restart the Jupyter kernel:\")\n",
    "    print(\"   Kernel ‚Üí Restart Kernel\")\n",
    "    print(\"   Then skip this cell and continue with Cell 2\")\n",
    "\n",
    "# Run installation\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ed09a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "241d7aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing libraries...\n",
      "Flower version: 1.22.0\n",
      "\n",
      "‚úÖ All libraries imported successfully!\n",
      "\n",
      "üìä Package Versions:\n",
      "   PyTorch: 2.9.0+cu130\n",
      "   Flower (flwr): 1.22.0\n",
      "   NumPy: 2.3.4\n",
      "   Pandas: 2.3.3\n",
      "   Scikit-learn: 1.7.2\n",
      "\n",
      "üñ•Ô∏è  Device: cuda\n",
      "   GPU: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "   CUDA Version: 13.0\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Import and verify all libraries\n",
    "# Run this after restarting the kernel to ensure everything is working\n",
    "\n",
    "print(\"Importing libraries...\")\n",
    "\n",
    "# Core libraries\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning utilities\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import sklearn\n",
    "\n",
    "# Progress bar\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Federated Learning\n",
    "import flwr as fl\n",
    "print(\"Flower version:\", fl.__version__)\n",
    "from flwr.simulation import start_simulation\n",
    "\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")\n",
    "print(f\"\\nüìä Package Versions:\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   Flower (flwr): {fl.__version__}\")\n",
    "print(f\"   NumPy: {np.__version__}\")\n",
    "print(f\"   Pandas: {pd.__version__}\")\n",
    "print(f\"   Scikit-learn: {sklearn.__version__}\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\nüñ•Ô∏è  Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"   Running on CPU (training will be slower)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e82ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration set successfully!\n",
      "\n",
      "üìã Project Configuration:\n",
      "   Number of Clients: 1\n",
      "   Number of Rounds: 1\n",
      "   Batch Size: 64\n",
      "   Local Epochs: 10\n",
      "   Learning Rate: 0.001\n",
      "   Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Global Configuration\n",
    "# This cell sets up all the configuration parameters for the project\n",
    "\n",
    "class Config:\n",
    "    \"\"\"Configuration class for the federated learning project\"\"\"\n",
    "    \n",
    "    # Random seed for reproducibility\n",
    "    SEED = 42\n",
    "    \n",
    "    # Dataset settings\n",
    "    DATASET_PATH = \"./data/HAM10000\"  # Path to HAM10000 dataset\n",
    "    IMAGE_SIZE = (224, 224)  # ResNet18 input size\n",
    "    NUM_CLASSES = 3  # melanoma, nevi, seborrheic keratoses\n",
    "    CLASS_NAMES = ['melanoma', 'nevi', 'seborrheic_keratoses']\n",
    "    \n",
    "    # Federated Learning settings\n",
    "    NUM_CLIENTS = 1  # Number of healthcare institutions\n",
    "    NUM_ROUNDS = 1  # Number of federated learning rounds\n",
    "    #NUM_MALICIOUS_CLIENTS = 2  # Number of clients to poison\n",
    "    \n",
    "    # Model training settings\n",
    "    BATCH_SIZE = 64\n",
    "    LOCAL_EPOCHS = 10  # Epochs per client per round\n",
    "    LEARNING_RATE = 0.001\n",
    "    \n",
    "    # Data split\n",
    "    TRAIN_SPLIT = 0.7\n",
    "    VAL_SPLIT = 0.15\n",
    "    TEST_SPLIT = 0.15\n",
    "    \n",
    "    # Anomaly detection thresholds\n",
    "    CONTAMINATION = 0.1  # Expected proportion of outliers\n",
    "    \n",
    "    # Device\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(Config.SEED)\n",
    "\n",
    "print(\"‚úÖ Configuration set successfully!\")\n",
    "print(f\"\\nüìã Project Configuration:\")\n",
    "print(f\"   Number of Clients: {Config.NUM_CLIENTS}\")\n",
    "print(f\"   Number of Rounds: {Config.NUM_ROUNDS}\")\n",
    "#print(f\"   Malicious Clients: {Config.NUM_MALICIOUS_CLIENTS}\")\n",
    "print(f\"   Batch Size: {Config.BATCH_SIZE}\")\n",
    "print(f\"   Local Epochs: {Config.LOCAL_EPOCHS}\")\n",
    "print(f\"   Learning Rate: {Config.LEARNING_RATE}\")\n",
    "print(f\"   Device: {Config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ecceebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° TIP: Uncomment the last line and run this cell to download\n",
      "   Or download manually and place in ./data/HAM10000/\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Download HAM10000 dataset using Kaggle API\n",
    "# NOTE: You need to set up Kaggle API credentials first\n",
    "# Instructions: https://www.kaggle.com/docs/api\n",
    "\n",
    "import subprocess\n",
    "import zipfile\n",
    "\n",
    "def download_ham10000():\n",
    "    \"\"\"Download HAM10000 dataset from Kaggle\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Check if kaggle is installed\n",
    "        try:\n",
    "            import kaggle\n",
    "            print(\"‚úÖ Kaggle API is installed\")\n",
    "        except ImportError:\n",
    "            print(\"üì¶ Installing Kaggle API...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"kaggle\", \"-q\"])\n",
    "            import kaggle\n",
    "        \n",
    "        # Create data directory\n",
    "        os.makedirs(\"./data\", exist_ok=True)\n",
    "        \n",
    "        # Download dataset\n",
    "        print(\"üì• Downloading HAM10000 dataset...\")\n",
    "        print(\"This may take several minutes (about 1.5 GB)...\\n\")\n",
    "        \n",
    "        subprocess.run([\n",
    "            \"kaggle\", \"datasets\", \"download\", \n",
    "            \"-d\", \"kmader/skin-cancer-mnist-ham10000\",\n",
    "            \"-p\", \"./data\"\n",
    "        ])\n",
    "        \n",
    "        # Extract dataset\n",
    "        print(\"\\nüì¶ Extracting dataset...\")\n",
    "        zip_path = \"./data/skin-cancer-mnist-ham10000.zip\"\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./data/HAM10000\")\n",
    "        \n",
    "        # Clean up zip file\n",
    "        os.remove(zip_path)\n",
    "        \n",
    "        print(\"‚úÖ Dataset downloaded and extracted successfully!\")\n",
    "        print(f\"   Location: ./data/HAM10000\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"\\nIf Kaggle API setup failed, please download manually:\")\n",
    "        print(\"1. Download from: https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000\")\n",
    "        print(\"2. Extract to: ./data/HAM10000/\")\n",
    "\n",
    "# Uncomment the line below to run the download\n",
    "# download_ham10000()\n",
    "\n",
    "print(\"üí° TIP: Uncomment the last line and run this cell to download\")\n",
    "print(\"   Or download manually and place in ./data/HAM10000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f94ec098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading HAM10000 dataset...\n",
      "‚úÖ Loaded metadata: 10015 images\n",
      "\n",
      "üìä Dataset Statistics:\n",
      "dx\n",
      "nv       6705\n",
      "mel      1113\n",
      "bkl      1099\n",
      "bcc       514\n",
      "akiec     327\n",
      "vasc      142\n",
      "df        115\n",
      "Name: count, dtype: int64\n",
      "\n",
      "‚úÖ Filtered to 3 classes: 8917 images\n",
      "\n",
      "Class distribution:\n",
      "   mel: 1113 images (label 0)\n",
      "   nv: 6705 images (label 1)\n",
      "   bkl: 1099 images (label 2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d056f4c37794a4e80958fc4df4aad16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/8917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Successfully loaded 8917 images\n",
      "\n",
      "‚úÖ Dataset preparation complete!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Dataset Loading and Preparation\n",
    "# This cell loads the HAM10000 dataset and prepares it for training\n",
    "\n",
    "class HAM10000Dataset(Dataset):\n",
    "    \"\"\"Custom Dataset class for HAM10000 skin lesion images\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_paths (list): List of paths to images\n",
    "            labels (list): List of labels (0, 1, or 2)\n",
    "            transform (callable, optional): Optional transform to be applied on images\n",
    "        \"\"\"\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get label\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "def load_and_prepare_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Load HAM10000 dataset and prepare it for federated learning\n",
    "    \n",
    "    Args:\n",
    "        dataset_path (str): Path to HAM10000 dataset directory\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Lists of image paths and corresponding labels\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìÇ Loading HAM10000 dataset...\")\n",
    "    \n",
    "    # Check if dataset exists\n",
    "    if not os.path.exists(dataset_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset not found at {dataset_path}\\n\"\n",
    "            \"Please download the HAM10000 dataset first (see Cell 4)\"\n",
    "        )\n",
    "    \n",
    "    # Load metadata\n",
    "    metadata_path = os.path.join(dataset_path, \"HAM10000_metadata.csv\")\n",
    "    \n",
    "    if not os.path.exists(metadata_path):\n",
    "        raise FileNotFoundError(\n",
    "            f\"Metadata file not found: {metadata_path}\\n\"\n",
    "            \"Make sure HAM10000_metadata.csv is in the dataset folder\"\n",
    "        )\n",
    "    \n",
    "    metadata = pd.read_csv(metadata_path)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded metadata: {len(metadata)} images\")\n",
    "    print(f\"\\nüìä Dataset Statistics:\")\n",
    "    print(metadata['dx'].value_counts())\n",
    "    \n",
    "    # Filter for the 3 classes we're using\n",
    "    # dx: diagnosis - mel (melanoma), nv (nevi), bkl (benign keratosis/seborrheic keratoses)\n",
    "    classes_to_use = {\n",
    "        'mel': 0,  # melanoma\n",
    "        'nv': 1,   # nevi\n",
    "        'bkl': 2   # seborrheic keratoses\n",
    "    }\n",
    "    \n",
    "    # Filter metadata\n",
    "    filtered_metadata = metadata[metadata['dx'].isin(classes_to_use.keys())].copy()\n",
    "    filtered_metadata['label'] = filtered_metadata['dx'].map(classes_to_use)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Filtered to 3 classes: {len(filtered_metadata)} images\")\n",
    "    print(\"\\nClass distribution:\")\n",
    "    for class_name, label in classes_to_use.items():\n",
    "        count = (filtered_metadata['label'] == label).sum()\n",
    "        print(f\"   {class_name}: {count} images (label {label})\")\n",
    "    \n",
    "    # Get image paths\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Check both image directories\n",
    "    img_dirs = [\n",
    "        os.path.join(dataset_path, \"HAM10000_images_part_1\"),\n",
    "        os.path.join(dataset_path, \"HAM10000_images_part_2\")\n",
    "    ]\n",
    "    \n",
    "    for _, row in tqdm(filtered_metadata.iterrows(), total=len(filtered_metadata), desc=\"Processing images\"):\n",
    "        image_id = row['image_id']\n",
    "        label = row['label']\n",
    "        \n",
    "        # Find image in either directory\n",
    "        img_found = False\n",
    "        for img_dir in img_dirs:\n",
    "            img_path = os.path.join(img_dir, f\"{image_id}.jpg\")\n",
    "            if os.path.exists(img_path):\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(label)\n",
    "                img_found = True\n",
    "                break\n",
    "        \n",
    "        if not img_found:\n",
    "            print(f\"Warning: Image not found: {image_id}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Successfully loaded {len(image_paths)} images\")\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "\n",
    "# Define image transformations\n",
    "def get_transforms():\n",
    "    \"\"\"\n",
    "    Get image transformations for training and validation\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_transform, val_transform)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Training transforms with data augmentation\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize(Config.IMAGE_SIZE),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Validation/Test transforms (no augmentation)\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize(Config.IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "try:\n",
    "    image_paths, labels = load_and_prepare_dataset(Config.DATASET_PATH)\n",
    "    train_transform, val_transform = get_transforms()\n",
    "    print(\"\\n‚úÖ Dataset preparation complete!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error loading dataset: {e}\")\n",
    "    print(\"Please make sure the HAM10000 dataset is downloaded and placed correctly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8569243e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Creating ResNet18 model for skin cancer classification...\n",
      "\n",
      "‚úÖ Loaded ResNet18 with pretrained ImageNet weights\n",
      "‚úÖ Model configured for 3 classes\n",
      "   Final layer: Linear(512 -> 3)\n",
      "\n",
      "üìä Model Summary:\n",
      "   Total parameters: 11,178,051\n",
      "   Trainable parameters: 11,178,051\n",
      "   Device: cuda\n",
      "\n",
      "üí° ResNet18 is ~23x lighter than VGG16!\n",
      "   ResNet18: ~11M parameters\n",
      "   VGG16: ~138M parameters\n",
      "\n",
      "‚úÖ Model created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: ResNet18 Model Definition\n",
    "# This cell defines the ResNet18 model for skin cancer classification\n",
    "\n",
    "class SkinCancerResNet18(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet18 model adapted for skin cancer classification\n",
    "    Uses pretrained weights from ImageNet for transfer learning\n",
    "    Much lighter than VGG16 - only ~11M parameters vs 138M\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=3, pretrained=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes (int): Number of output classes (default: 3)\n",
    "            pretrained (bool): Use pretrained ImageNet weights (default: True)\n",
    "        \"\"\"\n",
    "        super(SkinCancerResNet18, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet18 model\n",
    "        if pretrained:\n",
    "            self.resnet18 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "            print(\"‚úÖ Loaded ResNet18 with pretrained ImageNet weights\")\n",
    "        else:\n",
    "            self.resnet18 = models.resnet18(weights=None)\n",
    "            print(\"‚ö†Ô∏è  Loaded ResNet18 without pretrained weights\")\n",
    "        \n",
    "        # Get the number of input features for the final layer\n",
    "        num_features = self.resnet18.fc.in_features\n",
    "        \n",
    "        # Replace the final fully connected layer\n",
    "        # Original ResNet18 FC was for 1000 classes (ImageNet)\n",
    "        self.resnet18.fc = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        print(f\"‚úÖ Model configured for {num_classes} classes\")\n",
    "        print(f\"   Final layer: Linear({num_features} -> {num_classes})\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through the network\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input images [batch_size, 3, 224, 224]\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Class predictions [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        return self.resnet18(x)\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        \"\"\"\n",
    "        Extract features before the final classification layer\n",
    "        Useful for anomaly detection\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input images\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Extracted features [batch_size, 512]\n",
    "        \"\"\"\n",
    "        # Forward pass through all layers except the final FC\n",
    "        x = self.resnet18.conv1(x)\n",
    "        x = self.resnet18.bn1(x)\n",
    "        x = self.resnet18.relu(x)\n",
    "        x = self.resnet18.maxpool(x)\n",
    "        \n",
    "        x = self.resnet18.layer1(x)\n",
    "        x = self.resnet18.layer2(x)\n",
    "        x = self.resnet18.layer3(x)\n",
    "        x = self.resnet18.layer4(x)\n",
    "        \n",
    "        x = self.resnet18.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"\n",
    "    Create and initialize the ResNet18 model\n",
    "    \n",
    "    Returns:\n",
    "        SkinCancerResNet18: Initialized model on the configured device\n",
    "    \"\"\"\n",
    "    model = SkinCancerResNet18(num_classes=Config.NUM_CLASSES, pretrained=True)\n",
    "    model = model.to(Config.DEVICE)\n",
    "    \n",
    "    # Print model summary\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"\\nüìä Model Summary:\")\n",
    "    print(f\"   Total parameters: {total_params:,}\")\n",
    "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"   Device: {Config.DEVICE}\")\n",
    "    print(f\"\\nüí° ResNet18 is ~23x lighter than VGG16!\")\n",
    "    print(f\"   ResNet18: ~11M parameters\")\n",
    "    print(f\"   VGG16: ~138M parameters\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Create the model\n",
    "print(\"üî® Creating ResNet18 model for skin cancer classification...\\n\")\n",
    "model = create_model()\n",
    "print(\"\\n‚úÖ Model created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "104f7a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä PREPARING DATA FOR FEDERATED LEARNING\n",
      "======================================================================\n",
      "\n",
      "üß™ Creating global test set (15% of data)...\n",
      "‚úÖ Test set: 1337 images\n",
      "‚úÖ Remaining for clients: 7580 images\n",
      "\n",
      "üîÄ Splitting data among 1 clients...\n",
      "   Client 0: Train=6064, Val=1516\n",
      "\n",
      "‚úÖ Data split complete!\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Data preparation complete!\n",
      "   ‚Ä¢ 1 clients ready\n",
      "   ‚Ä¢ Test set: 1337 images\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Split Data Among Clients for Federated Learning\n",
    "# This distributes the dataset across multiple simulated healthcare institutions\n",
    "\n",
    "def split_data_for_federated_learning(image_paths, labels, num_clients=10):\n",
    "    \"\"\"\n",
    "    Split dataset among multiple clients for federated learning\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): List of image paths\n",
    "        labels (list): List of labels\n",
    "        num_clients (int): Number of clients to split data among\n",
    "    \n",
    "    Returns:\n",
    "        list: List of tuples (train_paths, train_labels, val_paths, val_labels) for each client\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüîÄ Splitting data among {num_clients} clients...\")\n",
    "    \n",
    "    # Convert to numpy arrays for easier manipulation\n",
    "    image_paths = np.array(image_paths)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Shuffle data\n",
    "    indices = np.arange(len(image_paths))\n",
    "    np.random.shuffle(indices)\n",
    "    image_paths = image_paths[indices]\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    # Split into num_clients chunks\n",
    "    client_data = []\n",
    "    samples_per_client = len(image_paths) // num_clients\n",
    "    \n",
    "    for i in range(num_clients):\n",
    "        start_idx = i * samples_per_client\n",
    "        \n",
    "        # Last client gets remaining samples\n",
    "        if i == num_clients - 1:\n",
    "            end_idx = len(image_paths)\n",
    "        else:\n",
    "            end_idx = (i + 1) * samples_per_client\n",
    "        \n",
    "        # Get client's data\n",
    "        client_paths = image_paths[start_idx:end_idx]\n",
    "        client_labels = labels[start_idx:end_idx]\n",
    "        \n",
    "        # Split into train (80%) and validation (20%)\n",
    "        split_point = int(len(client_paths) * 0.8)\n",
    "        \n",
    "        train_paths = client_paths[:split_point]\n",
    "        train_labels = client_labels[:split_point]\n",
    "        val_paths = client_paths[split_point:]\n",
    "        val_labels = client_labels[split_point:]\n",
    "        \n",
    "        client_data.append((train_paths, train_labels, val_paths, val_labels))\n",
    "        \n",
    "        print(f\"   Client {i}: Train={len(train_paths)}, Val={len(val_paths)}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Data split complete!\")\n",
    "    return client_data\n",
    "\n",
    "\n",
    "# Create global test set (separate from client data)\n",
    "def create_test_set(image_paths, labels, test_size=0.15):\n",
    "    \"\"\"\n",
    "    Create a global test set for server evaluation\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): All image paths\n",
    "        labels (list): All labels\n",
    "        test_size (float): Proportion of data for testing\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (test_paths, test_labels, remaining_paths, remaining_labels)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nüß™ Creating global test set ({int(test_size*100)}% of data)...\")\n",
    "    \n",
    "    # Convert to numpy\n",
    "    image_paths = np.array(image_paths)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Shuffle\n",
    "    indices = np.arange(len(image_paths))\n",
    "    np.random.shuffle(indices)\n",
    "    image_paths = image_paths[indices]\n",
    "    labels = labels[indices]\n",
    "    \n",
    "    # Split\n",
    "    split_point = int(len(image_paths) * test_size)\n",
    "    \n",
    "    test_paths = image_paths[:split_point]\n",
    "    test_labels = labels[:split_point]\n",
    "    remaining_paths = image_paths[split_point:]\n",
    "    remaining_labels = labels[split_point:]\n",
    "    \n",
    "    print(f\"‚úÖ Test set: {len(test_paths)} images\")\n",
    "    print(f\"‚úÖ Remaining for clients: {len(remaining_paths)} images\")\n",
    "    \n",
    "    return test_paths, test_labels, remaining_paths, remaining_labels\n",
    "\n",
    "\n",
    "# Execute data splitting\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä PREPARING DATA FOR FEDERATED LEARNING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create test set first\n",
    "test_paths, test_labels, client_paths, client_labels = create_test_set(\n",
    "    image_paths, labels, test_size=0.15\n",
    ")\n",
    "\n",
    "# Split remaining data among clients\n",
    "client_data = split_data_for_federated_learning(\n",
    "    client_paths, client_labels, num_clients=Config.NUM_CLIENTS\n",
    ")\n",
    "\n",
    "# Create test dataset\n",
    "test_dataset = HAM10000Dataset(test_paths, test_labels, transform=val_transform)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"‚úÖ Data preparation complete!\")\n",
    "print(f\"   ‚Ä¢ {Config.NUM_CLIENTS} clients ready\")\n",
    "print(f\"   ‚Ä¢ Test set: {len(test_dataset)} images\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dcf1a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FlowerClient class defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Federated Learning Client Implementation\n",
    "# Each client represents a healthcare institution with local data\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    \"\"\"\n",
    "    Flower client for federated learning\n",
    "    Trains model locally and communicates with central server\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cid, train_data, val_data, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cid (int): Client ID\n",
    "            train_data (tuple): (image_paths, labels) for training\n",
    "            val_data (tuple): (image_paths, labels) for validation\n",
    "            device: torch device (CPU or CUDA)\n",
    "        \"\"\"\n",
    "        self.cid = cid\n",
    "        self.device = device\n",
    "        \n",
    "        # Create datasets\n",
    "        train_paths, train_labels = train_data\n",
    "        val_paths, val_labels = val_data\n",
    "        \n",
    "        self.train_dataset = HAM10000Dataset(\n",
    "            train_paths, train_labels, transform=train_transform\n",
    "        )\n",
    "        self.val_dataset = HAM10000Dataset(\n",
    "            val_paths, val_labels, transform=val_transform\n",
    "        )\n",
    "        \n",
    "        # Create data loaders\n",
    "        self.train_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=0,  # Set to 0 for Windows compatibility\n",
    "            pin_memory=True if device.type == 'cuda' else False\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True if device.type == 'cuda' else False\n",
    "        )\n",
    "        \n",
    "        # Create model\n",
    "        self.model = create_model()\n",
    "        \n",
    "        # Loss and optimizer\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=Config.LEARNING_RATE)\n",
    "        \n",
    "        print(f\"‚úÖ Client {cid} initialized: Train={len(self.train_dataset)}, Val={len(self.val_dataset)}\")\n",
    "    \n",
    "    def get_parameters(self, config):\n",
    "        \"\"\"Get model parameters as numpy arrays\"\"\"\n",
    "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
    "    \n",
    "    def set_parameters(self, parameters):\n",
    "        \"\"\"Set model parameters from numpy arrays\"\"\"\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "    def fit(self, parameters, config):\n",
    "        \"\"\"Train model on local data\"\"\"\n",
    "        \n",
    "        # Set parameters from server\n",
    "        self.set_parameters(parameters)\n",
    "        \n",
    "        # Get number of epochs from config\n",
    "        epochs = config.get(\"local_epochs\", Config.LOCAL_EPOCHS)\n",
    "        \n",
    "        print(f\"\\nüèãÔ∏è  Client {self.cid} training for {epochs} epochs...\")\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            # Training loop\n",
    "            progress_bar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "            \n",
    "            for images, labels in progress_bar:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{100 * correct / total:.2f}%'\n",
    "                })\n",
    "            \n",
    "            # Calculate epoch metrics\n",
    "            avg_loss = epoch_loss / len(self.train_loader)\n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            print(f\"  Epoch {epoch+1}: Loss={avg_loss:.4f}, Accuracy={accuracy:.2f}%\")\n",
    "        \n",
    "        # Return updated parameters and metrics\n",
    "        return self.get_parameters(config={}), len(self.train_dataset), {\n",
    "            \"client_id\": self.cid,\n",
    "            \"train_loss\": float(avg_loss),\n",
    "            \"train_accuracy\": float(accuracy)\n",
    "        }\n",
    "    \n",
    "    def evaluate(self, parameters, config):\n",
    "        \"\"\"Evaluate model on validation data\"\"\"\n",
    "        \n",
    "        # Set parameters from server\n",
    "        self.set_parameters(parameters)\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.val_loader:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_loss = val_loss / len(self.val_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        return float(avg_loss), len(self.val_dataset), {\"val_accuracy\": float(accuracy)}\n",
    "\n",
    "\n",
    "print(\"‚úÖ FlowerClient class defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ab8a962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Server evaluation function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Server-Side Evaluation Function\n",
    "# Evaluates global model on centralized test set\n",
    "\n",
    "def get_evaluate_fn(test_dataset, device):\n",
    "    \"\"\"\n",
    "    Return evaluation function for server\n",
    "    \n",
    "    Args:\n",
    "        test_dataset: PyTorch dataset for testing\n",
    "        device: torch device\n",
    "    \n",
    "    Returns:\n",
    "        function: Evaluation function\n",
    "    \"\"\"\n",
    "    \n",
    "    def evaluate(server_round, parameters, config):\n",
    "        \"\"\"\n",
    "        Evaluate global model on test set\n",
    "        \n",
    "        Args:\n",
    "            server_round (int): Current round number\n",
    "            parameters: Model parameters\n",
    "            config: Configuration dict\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (loss, metrics_dict)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create model and set parameters\n",
    "        model = create_model()\n",
    "        params_dict = zip(model.state_dict().keys(), parameters)\n",
    "        state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "        model.load_state_dict(state_dict, strict=True)\n",
    "        model.eval()\n",
    "        \n",
    "        # Create test loader\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=Config.BATCH_SIZE,\n",
    "            shuffle=False,\n",
    "            num_workers=0\n",
    "        )\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        print(f\"\\nüîç Server evaluating global model (Round {server_round})...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                test_loss += loss.item()\n",
    "        \n",
    "        avg_loss = test_loss / len(test_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        print(f\"  Global Test: Loss={avg_loss:.4f}, Accuracy={accuracy:.2f}%\")\n",
    "        \n",
    "        return float(avg_loss), {\"accuracy\": float(accuracy)}\n",
    "    \n",
    "    return evaluate\n",
    "\n",
    "\n",
    "print(\"‚úÖ Server evaluation function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a44270ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded ResNet18 with pretrained ImageNet weights\n",
      "‚úÖ Model configured for 3 classes\n",
      "   Final layer: Linear(512 -> 3)\n",
      "\n",
      "üìä Model Summary:\n",
      "   Total parameters: 11,178,051\n",
      "   Trainable parameters: 11,178,051\n",
      "   Device: cuda\n",
      "\n",
      "üí° ResNet18 is ~23x lighter than VGG16!\n",
      "   ResNet18: ~11M parameters\n",
      "   VGG16: ~138M parameters\n",
      "‚úÖ FedAvg strategy configured!\n",
      "   ‚Ä¢ Clients per round: 1\n",
      "   ‚Ä¢ Local epochs: 10\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: FedAvg Strategy Configuration\n",
    "# Configures how the server aggregates client updates\n",
    "\n",
    "def weighted_average(metrics):\n",
    "    \"\"\"Aggregate metrics using weighted average\"\"\"\n",
    "    \n",
    "    # Extract number of examples and metrics\n",
    "    total_examples = sum([num_examples for num_examples, _ in metrics])\n",
    "    \n",
    "    if not metrics:\n",
    "        return {}\n",
    "    \n",
    "    aggregated = {}\n",
    "    metric_keys = metrics[0][1].keys()\n",
    "    \n",
    "    for key in metric_keys:\n",
    "        if isinstance(metrics[0][1][key], (int, float)):\n",
    "            weighted_sum = sum([num_examples * m[key] for num_examples, m in metrics])\n",
    "            aggregated[key] = weighted_sum / total_examples\n",
    "    \n",
    "    return aggregated\n",
    "\n",
    "\n",
    "def fit_config(server_round):\n",
    "    \"\"\"Configuration sent to clients for training\"\"\"\n",
    "    \n",
    "    config = {\n",
    "        \"server_round\": server_round,\n",
    "        \"local_epochs\": Config.LOCAL_EPOCHS,\n",
    "    }\n",
    "    return config\n",
    "\n",
    "\n",
    "# Create initial model to get parameters\n",
    "initial_model = create_model()\n",
    "initial_parameters = [val.cpu().numpy() for _, val in initial_model.state_dict().items()]\n",
    "\n",
    "# Create FedAvg strategy\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit=1.0,  # Use all clients for training\n",
    "    fraction_evaluate=1.0,  # Use all clients for evaluation\n",
    "    min_fit_clients=Config.NUM_CLIENTS,\n",
    "    min_evaluate_clients=Config.NUM_CLIENTS,\n",
    "    min_available_clients=Config.NUM_CLIENTS,\n",
    "    evaluate_fn=get_evaluate_fn(test_dataset, Config.DEVICE),\n",
    "    on_fit_config_fn=fit_config,\n",
    "    fit_metrics_aggregation_fn=weighted_average,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    initial_parameters=fl.common.ndarrays_to_parameters(initial_parameters),\n",
    ")\n",
    "\n",
    "print(\"‚úÖ FedAvg strategy configured!\")\n",
    "print(f\"   ‚Ä¢ Clients per round: {Config.NUM_CLIENTS}\")\n",
    "print(f\"   ‚Ä¢ Local epochs: {Config.LOCAL_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7558767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Client factory function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Client Function Factory\n",
    "# Creates client instances for Flower simulation\n",
    "\n",
    "def client_fn(cid):\n",
    "    \"\"\"\n",
    "    Create a Flower client instance\n",
    "    \n",
    "    Args:\n",
    "        cid (str): Client ID as string\n",
    "    \n",
    "    Returns:\n",
    "        FlowerClient: Client instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert client ID to integer\n",
    "    client_id = int(cid)\n",
    "    \n",
    "    # Get client's data\n",
    "    train_paths, train_labels, val_paths, val_labels = client_data[client_id]\n",
    "    \n",
    "    # Create and return client\n",
    "    return FlowerClient(\n",
    "        cid=client_id,\n",
    "        train_data=(train_paths, train_labels),\n",
    "        val_data=(val_paths, val_labels),\n",
    "        device=Config.DEVICE\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"‚úÖ Client factory function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df41f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Start Federated Learning Training (WITHOUT Ray)\n",
    "# Sequential client training - compatible with Python 3.13+\n",
    "\n",
    "import time\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üöÄ STARTING FEDERATED LEARNING TRAINING (Sequential Mode)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚öôÔ∏è  Training Configuration:\n",
    "   ‚Ä¢ Number of Rounds: {Config.NUM_ROUNDS}\n",
    "   ‚Ä¢ Number of Clients: {Config.NUM_CLIENTS}\n",
    "   ‚Ä¢ Local Epochs per Round: {Config.LOCAL_EPOCHS}\n",
    "   ‚Ä¢ Batch Size: {Config.BATCH_SIZE}\n",
    "   ‚Ä¢ Learning Rate: {Config.LEARNING_RATE}\n",
    "   ‚Ä¢ Device: {Config.DEVICE}\n",
    "\n",
    "‚è±Ô∏è  Estimated Time: ~{Config.NUM_ROUNDS * 30} minutes\n",
    "   (Sequential training - one client at a time)\n",
    "\n",
    "‚ö†Ô∏è  NOTE: Using sequential training (no Ray required)\n",
    "   ‚Ä¢ Clients train one after another (not in parallel)\n",
    "   ‚Ä¢ More compatible but slower than parallel simulation\n",
    "   ‚Ä¢ Perfect for Python 3.13+\n",
    "\"\"\")\n",
    "\n",
    "# Storage for training history\n",
    "training_history = {\n",
    "    'losses_centralized': [],\n",
    "    'metrics_centralized': [],\n",
    "    'losses_distributed': [],\n",
    "    'metrics_distributed': [],\n",
    "}\n",
    "\n",
    "# Create global model\n",
    "print(\"\\nüèóÔ∏è  Initializing global model...\")\n",
    "global_model = create_model()\n",
    "global_parameters = [val.cpu().numpy() for _, val in global_model.state_dict().items()]\n",
    "\n",
    "# Create all clients\n",
    "print(f\"\\nüë• Creating {Config.NUM_CLIENTS} clients...\")\n",
    "clients = []\n",
    "for cid in range(Config.NUM_CLIENTS):\n",
    "    train_paths, train_labels, val_paths, val_labels = client_data[cid]\n",
    "    client = FlowerClient(\n",
    "        cid=cid,\n",
    "        train_data=(train_paths, train_labels),\n",
    "        val_data=(val_paths, val_labels),\n",
    "        device=Config.DEVICE\n",
    "    )\n",
    "    clients.append(client)\n",
    "\n",
    "print(f\"‚úÖ All {Config.NUM_CLIENTS} clients created!\\n\")\n",
    "\n",
    "# Training configuration\n",
    "fit_config = {\n",
    "    \"local_epochs\": Config.LOCAL_EPOCHS,\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üèãÔ∏è  STARTING FEDERATED TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Main federated learning loop\n",
    "for round_num in range(1, Config.NUM_ROUNDS + 1):\n",
    "    \n",
    "    round_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìç ROUND {round_num}/{Config.NUM_ROUNDS}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Store client results for this round\n",
    "    client_results = []\n",
    "    client_metrics = []\n",
    "    \n",
    "    # Train each client sequentially\n",
    "    print(f\"\\nüîÑ Training clients...\")\n",
    "    \n",
    "    for client_idx, client in enumerate(clients):\n",
    "        \n",
    "        print(f\"\\n--- Client {client_idx} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Client trains on local data\n",
    "            updated_params, num_examples, metrics = client.fit(global_parameters, fit_config)\n",
    "            \n",
    "            # Store results\n",
    "            client_results.append((updated_params, num_examples))\n",
    "            client_metrics.append((num_examples, metrics))\n",
    "            \n",
    "            print(f\"‚úÖ Client {client_idx} completed: \"\n",
    "                  f\"Loss={metrics['train_loss']:.4f}, \"\n",
    "                  f\"Accuracy={metrics['train_accuracy']:.2f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Client {client_idx} failed: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Aggregate client updates (FedAvg)\n",
    "    print(f\"\\nüîÑ Aggregating updates from {len(client_results)} clients...\")\n",
    "    \n",
    "    if len(client_results) > 0:\n",
    "        # Calculate weighted average of parameters\n",
    "        total_examples = sum([num_examples for _, num_examples in client_results])\n",
    "        \n",
    "        # Initialize aggregated parameters\n",
    "        aggregated_params = [\n",
    "            np.zeros_like(param) for param in client_results[0][0]\n",
    "        ]\n",
    "        \n",
    "        # Weighted average\n",
    "        for client_params, num_examples in client_results:\n",
    "            weight = num_examples / total_examples\n",
    "            for i, param in enumerate(client_params):\n",
    "                aggregated_params[i] += param * weight\n",
    "        \n",
    "        # Update global parameters\n",
    "        global_parameters = aggregated_params\n",
    "        \n",
    "        print(f\"‚úÖ Aggregation complete!\")\n",
    "        \n",
    "        # Aggregate client metrics\n",
    "        if client_metrics:\n",
    "            total_examples = sum([num for num, _ in client_metrics])\n",
    "            avg_train_loss = sum([num * m['train_loss'] for num, m in client_metrics]) / total_examples\n",
    "            avg_train_acc = sum([num * m['train_accuracy'] for num, m in client_metrics]) / total_examples\n",
    "            \n",
    "            training_history['losses_distributed'].append(float(avg_train_loss))\n",
    "            training_history['metrics_distributed'].append({\n",
    "                'train_accuracy': float(avg_train_acc)\n",
    "            })\n",
    "    \n",
    "    # Server-side evaluation on test set\n",
    "    print(f\"\\nüîç Server evaluating global model...\")\n",
    "    \n",
    "    # Set global model parameters\n",
    "    params_dict = zip(global_model.state_dict().keys(), global_parameters)\n",
    "    state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "    global_model.load_state_dict(state_dict, strict=True)\n",
    "    global_model.eval()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(Config.DEVICE)\n",
    "            labels = labels.to(Config.DEVICE)\n",
    "            \n",
    "            outputs = global_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    \n",
    "    # Store centralized metrics\n",
    "    training_history['losses_centralized'].append(float(avg_test_loss))\n",
    "    training_history['metrics_centralized'].append({\n",
    "        'accuracy': float(test_accuracy)\n",
    "    })\n",
    "    \n",
    "    # Print round summary\n",
    "    round_time = time.time() - round_start_time\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìä ROUND {round_num} SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"   Global Test Loss: {avg_test_loss:.4f}\")\n",
    "    print(f\"   Global Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"   Round Time: {round_time/60:.1f} minutes\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create history object compatible with Flower's format\n",
    "class TrainingHistory:\n",
    "    \"\"\"Mimics Flower's History object\"\"\"\n",
    "    def __init__(self, history_dict, final_params):\n",
    "        self.losses_centralized = history_dict['losses_centralized']\n",
    "        self.metrics_centralized = history_dict['metrics_centralized']\n",
    "        self.losses_distributed = history_dict['losses_distributed']\n",
    "        self.metrics_distributed = history_dict['metrics_distributed']\n",
    "        self.parameters = final_params\n",
    "\n",
    "# Create final history object\n",
    "final_params_flower = fl.common.ndarrays_to_parameters(global_parameters)\n",
    "history = TrainingHistory(training_history, final_params_flower)\n",
    "\n",
    "print(f\"\\n‚úÖ Training history saved!\")\n",
    "print(f\"   ‚Ä¢ Total rounds completed: {Config.NUM_ROUNDS}\")\n",
    "print(f\"   ‚Ä¢ Final test accuracy: {training_history['metrics_centralized'][-1]['accuracy']:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Final test loss: {training_history['losses_centralized'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4512a17a",
   "metadata": {},
   "source": [
    "###memory efficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "888434cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üöÄ STARTING FEDERATED LEARNING TRAINING (Memory-Efficient Mode)\n",
      "======================================================================\n",
      "\n",
      "‚öôÔ∏è  Training Configuration:\n",
      "   ‚Ä¢ Number of Rounds: 1\n",
      "   ‚Ä¢ Number of Clients: 1\n",
      "   ‚Ä¢ Local Epochs per Round: 10\n",
      "   ‚Ä¢ Batch Size: 64\n",
      "   ‚Ä¢ Learning Rate: 0.001\n",
      "   ‚Ä¢ Device: cuda\n",
      "\n",
      "‚è±Ô∏è  Estimated Time: ~30 minutes\n",
      "\n",
      "üíæ Memory-Efficient Mode:\n",
      "   ‚Ä¢ Creates one client at a time\n",
      "   ‚Ä¢ Clears GPU memory after each client\n",
      "   ‚Ä¢ Perfect for 4GB GPUs\n",
      "\n",
      "\n",
      "üèóÔ∏è  Initializing global model...\n",
      "‚úÖ Loaded ResNet18 with pretrained ImageNet weights\n",
      "‚úÖ Model configured for 3 classes\n",
      "   Final layer: Linear(512 -> 3)\n",
      "\n",
      "üìä Model Summary:\n",
      "   Total parameters: 11,178,051\n",
      "   Trainable parameters: 11,178,051\n",
      "   Device: cuda\n",
      "\n",
      "üí° ResNet18 is ~23x lighter than VGG16!\n",
      "   ResNet18: ~11M parameters\n",
      "   VGG16: ~138M parameters\n",
      "‚úÖ Global model initialized!\n",
      "üíæ GPU Memory: 0.11 GB allocated\n",
      "\n",
      "======================================================================\n",
      "üèãÔ∏è  STARTING FEDERATED TRAINING\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "üìç ROUND 1/1\n",
      "======================================================================\n",
      "\n",
      "üîÑ Training clients...\n",
      "\n",
      "--- Client 0 ---\n",
      "‚úÖ Loaded ResNet18 with pretrained ImageNet weights\n",
      "‚úÖ Model configured for 3 classes\n",
      "   Final layer: Linear(512 -> 3)\n",
      "\n",
      "üìä Model Summary:\n",
      "   Total parameters: 11,178,051\n",
      "   Trainable parameters: 11,178,051\n",
      "   Device: cuda\n",
      "\n",
      "üí° ResNet18 is ~23x lighter than VGG16!\n",
      "   ResNet18: ~11M parameters\n",
      "   VGG16: ~138M parameters\n",
      "‚úÖ Client 0 initialized: Train=6064, Val=1516\n",
      "\n",
      "üèãÔ∏è  Client 0 training for 10 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7651a835b80745b2982d77b89f54bb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: Loss=0.6224, Accuracy=76.55%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3ac43d7f1b447081cfa75fe38d5a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: Loss=0.5084, Accuracy=78.99%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763a50e5b7ad48578db47dd9bb15a461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/10:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: Loss=0.4910, Accuracy=80.52%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fb22b3fd72434d9a4a3832f9172ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/10:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: Loss=0.4912, Accuracy=81.02%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ef7065ff294a03a545a65cdb9e9549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/10:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: Loss=0.4794, Accuracy=81.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1f549d2bef45de8003711c3f77652e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/10:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 6: Loss=0.4578, Accuracy=81.93%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417a921bf1c14a8984f377ce6515130d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/10:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 7: Loss=0.4692, Accuracy=81.22%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44c63d90def4cda9febccae37e31b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/10:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 8: Loss=0.4479, Accuracy=81.91%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbabdbc9187c4a2fac68b0eb6d1bc62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/10:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 9: Loss=0.4514, Accuracy=82.16%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64c2fef790ca4ee18d6485afda7ede43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/10:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10: Loss=0.4458, Accuracy=82.70%\n",
      "‚úÖ Client 0 completed: Loss=0.4458, Accuracy=82.70%\n",
      "üíæ GPU Memory after cleanup: 0.11 GB\n",
      "\n",
      "üîÑ Aggregating updates from 1 clients...\n",
      "‚úÖ Aggregation complete!\n",
      "\n",
      "üîç Server evaluating global model...\n",
      "‚úÖ Loaded ResNet18 with pretrained ImageNet weights\n",
      "‚úÖ Model configured for 3 classes\n",
      "   Final layer: Linear(512 -> 3)\n",
      "\n",
      "üìä Model Summary:\n",
      "   Total parameters: 11,178,051\n",
      "   Trainable parameters: 11,178,051\n",
      "   Device: cuda\n",
      "\n",
      "üí° ResNet18 is ~23x lighter than VGG16!\n",
      "   ResNet18: ~11M parameters\n",
      "   VGG16: ~138M parameters\n",
      "\n",
      "======================================================================\n",
      "üìä ROUND 1 SUMMARY\n",
      "======================================================================\n",
      "   Global Test Loss: 0.4850\n",
      "   Global Test Accuracy: 81.38%\n",
      "   Round Time: 15.9 minutes\n",
      "   GPU Memory: 0.15 GB\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "‚úÖ TRAINING COMPLETED!\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Training history saved!\n",
      "   ‚Ä¢ Total rounds completed: 1\n",
      "   ‚Ä¢ Final test accuracy: 81.38%\n",
      "   ‚Ä¢ Final test loss: 0.4850\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Start Federated Learning Training (Memory Efficient - No Ray)\n",
    "# Creates clients on-demand and clears memory after each client\n",
    "\n",
    "import time\n",
    "from typing import List, Tuple, Dict\n",
    "import gc\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üöÄ STARTING FEDERATED LEARNING TRAINING (Memory-Efficient Mode)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "‚öôÔ∏è  Training Configuration:\n",
    "   ‚Ä¢ Number of Rounds: {Config.NUM_ROUNDS}\n",
    "   ‚Ä¢ Number of Clients: {Config.NUM_CLIENTS}\n",
    "   ‚Ä¢ Local Epochs per Round: {Config.LOCAL_EPOCHS}\n",
    "   ‚Ä¢ Batch Size: {Config.BATCH_SIZE}\n",
    "   ‚Ä¢ Learning Rate: {Config.LEARNING_RATE}\n",
    "   ‚Ä¢ Device: {Config.DEVICE}\n",
    "\n",
    "‚è±Ô∏è  Estimated Time: ~{Config.NUM_ROUNDS * 30} minutes\n",
    "\n",
    "üíæ Memory-Efficient Mode:\n",
    "   ‚Ä¢ Creates one client at a time\n",
    "   ‚Ä¢ Clears GPU memory after each client\n",
    "   ‚Ä¢ Perfect for 4GB GPUs\n",
    "\"\"\")\n",
    "\n",
    "# Storage for training history\n",
    "training_history = {\n",
    "    'losses_centralized': [],\n",
    "    'metrics_centralized': [],\n",
    "    'losses_distributed': [],\n",
    "    'metrics_distributed': [],\n",
    "}\n",
    "\n",
    "# Create global model\n",
    "print(\"\\nüèóÔ∏è  Initializing global model...\")\n",
    "global_model = create_model()\n",
    "global_parameters = [val.cpu().numpy() for _, val in global_model.state_dict().items()]\n",
    "\n",
    "# Delete global_model to free memory (we only need parameters)\n",
    "del global_model\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"‚úÖ Global model initialized!\")\n",
    "print(f\"üíæ GPU Memory: {torch.cuda.memory_allocated()/1e9:.2f} GB allocated\")\n",
    "\n",
    "# Training configuration\n",
    "fit_config = {\n",
    "    \"local_epochs\": Config.LOCAL_EPOCHS,\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üèãÔ∏è  STARTING FEDERATED TRAINING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Main federated learning loop\n",
    "for round_num in range(1, Config.NUM_ROUNDS + 1):\n",
    "    \n",
    "    round_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìç ROUND {round_num}/{Config.NUM_ROUNDS}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Store client results for this round\n",
    "    client_results = []\n",
    "    client_metrics = []\n",
    "    \n",
    "    # Train each client sequentially (CREATE AND DESTROY EACH CLIENT)\n",
    "    print(f\"\\nüîÑ Training clients...\")\n",
    "    \n",
    "    for client_idx in range(Config.NUM_CLIENTS):\n",
    "        \n",
    "        print(f\"\\n--- Client {client_idx} ---\")\n",
    "        \n",
    "        try:\n",
    "            # CREATE CLIENT (only this one client exists in memory)\n",
    "            train_paths, train_labels, val_paths, val_labels = client_data[client_idx]\n",
    "            client = FlowerClient(\n",
    "                cid=client_idx,\n",
    "                train_data=(train_paths, train_labels),\n",
    "                val_data=(val_paths, val_labels),\n",
    "                device=Config.DEVICE\n",
    "            )\n",
    "            \n",
    "            # Client trains on local data\n",
    "            updated_params, num_examples, metrics = client.fit(global_parameters, fit_config)\n",
    "            \n",
    "            # Store results\n",
    "            client_results.append((updated_params, num_examples))\n",
    "            client_metrics.append((num_examples, metrics))\n",
    "            \n",
    "            print(f\"‚úÖ Client {client_idx} completed: \"\n",
    "                  f\"Loss={metrics['train_loss']:.4f}, \"\n",
    "                  f\"Accuracy={metrics['train_accuracy']:.2f}%\")\n",
    "            \n",
    "            # CRITICAL: DELETE CLIENT AND FREE MEMORY\n",
    "            del client\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "            print(f\"üíæ GPU Memory after cleanup: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Client {client_idx} failed: {e}\")\n",
    "            # Clean up even on failure\n",
    "            if 'client' in locals():\n",
    "                del client\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            continue\n",
    "    \n",
    "    # Aggregate client updates (FedAvg)\n",
    "    print(f\"\\nüîÑ Aggregating updates from {len(client_results)} clients...\")\n",
    "    \n",
    "    if len(client_results) > 0:\n",
    "        # Calculate weighted average of parameters\n",
    "        total_examples = sum([num_examples for _, num_examples in client_results])\n",
    "        \n",
    "        # Initialize aggregated parameters\n",
    "        aggregated_params = [\n",
    "            np.zeros_like(param, dtype=np.float64) for param in client_results[0][0]\n",
    "        ]\n",
    "\n",
    "        total_examples = sum([num_examples for _, num_examples in client_results])\n",
    "\n",
    "        # Weighted average\n",
    "        for client_params, num_examples in client_results:\n",
    "            weight = float(num_examples) / float(total_examples)\n",
    "            for i, param in enumerate(client_params):\n",
    "                aggregated_params[i] += param.astype(np.float64) * weight\n",
    "        \n",
    "        # Update global parameters\n",
    "        global_parameters = aggregated_params\n",
    "        \n",
    "        print(f\"‚úÖ Aggregation complete!\")\n",
    "        \n",
    "        # Aggregate client metrics\n",
    "        if client_metrics:\n",
    "            total_examples = sum([num for num, _ in client_metrics])\n",
    "            avg_train_loss = sum([num * m['train_loss'] for num, m in client_metrics]) / total_examples\n",
    "            avg_train_acc = sum([num * m['train_accuracy'] for num, m in client_metrics]) / total_examples\n",
    "            \n",
    "            training_history['losses_distributed'].append(float(avg_train_loss))\n",
    "            training_history['metrics_distributed'].append({\n",
    "                'train_accuracy': float(avg_train_acc)\n",
    "            })\n",
    "    \n",
    "    # Server-side evaluation on test set\n",
    "    print(f\"\\nüîç Server evaluating global model...\")\n",
    "    \n",
    "    # Create temporary model for evaluation\n",
    "    eval_model = create_model()\n",
    "    \n",
    "    # Set global model parameters\n",
    "    params_dict = zip(eval_model.state_dict().keys(), global_parameters)\n",
    "    state_dict = OrderedDict({k: torch.from_numpy(v.astype(np.float32)) for k, v in params_dict})\n",
    "    eval_model.load_state_dict(state_dict, strict=True)\n",
    "    eval_model.eval()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(Config.DEVICE)\n",
    "            labels = labels.to(Config.DEVICE)\n",
    "            \n",
    "            outputs = eval_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            test_loss += loss.item()\n",
    "    \n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "    \n",
    "    # Store centralized metrics\n",
    "    training_history['losses_centralized'].append(float(avg_test_loss))\n",
    "    training_history['metrics_centralized'].append({\n",
    "        'accuracy': float(test_accuracy)\n",
    "    })\n",
    "    \n",
    "    # DELETE evaluation model and free memory\n",
    "    del eval_model\n",
    "    del test_loader\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Print round summary\n",
    "    round_time = time.time() - round_start_time\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üìä ROUND {round_num} SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"   Global Test Loss: {avg_test_loss:.4f}\")\n",
    "    print(f\"   Global Test Accuracy: {test_accuracy:.2f}%\")\n",
    "    print(f\"   Round Time: {round_time/60:.1f} minutes\")\n",
    "    print(f\"   GPU Memory: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ TRAINING COMPLETED!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create history object compatible with Flower's format\n",
    "class TrainingHistory:\n",
    "    \"\"\"Mimics Flower's History object\"\"\"\n",
    "    def __init__(self, history_dict, final_params):\n",
    "        self.losses_centralized = history_dict['losses_centralized']\n",
    "        self.metrics_centralized = history_dict['metrics_centralized']\n",
    "        self.losses_distributed = history_dict['losses_distributed']\n",
    "        self.metrics_distributed = history_dict['metrics_distributed']\n",
    "        self.parameters = final_params\n",
    "\n",
    "# Create final history object\n",
    "final_params_flower = fl.common.ndarrays_to_parameters(global_parameters)\n",
    "history = TrainingHistory(training_history, final_params_flower)\n",
    "\n",
    "print(f\"\\n‚úÖ Training history saved!\")\n",
    "print(f\"   ‚Ä¢ Total rounds completed: {Config.NUM_ROUNDS}\")\n",
    "print(f\"   ‚Ä¢ Final test accuracy: {training_history['metrics_centralized'][-1]['accuracy']:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Final test loss: {training_history['losses_centralized'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "136b2b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üíæ SAVING RESULTS\n",
      "======================================================================\n",
      "‚úÖ Loaded ResNet18 with pretrained ImageNet weights\n",
      "‚úÖ Model configured for 3 classes\n",
      "   Final layer: Linear(512 -> 3)\n",
      "\n",
      "üìä Model Summary:\n",
      "   Total parameters: 11,178,051\n",
      "   Trainable parameters: 11,178,051\n",
      "   Device: cuda\n",
      "\n",
      "üí° ResNet18 is ~23x lighter than VGG16!\n",
      "   ResNet18: ~11M parameters\n",
      "   VGG16: ~138M parameters\n",
      "‚úÖ Model saved: ./results/fl_training_20251030_210659\\final_model.pth\n",
      "‚úÖ History saved: ./results/fl_training_20251030_210659\\training_history.pkl\n",
      "‚úÖ Config saved: ./results/fl_training_20251030_210659\\config.txt\n",
      "\n",
      "üìÅ All results saved to: ./results/fl_training_20251030_210659\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Save Training Results\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Create results directory\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results_dir = f\"./results/fl_training_{timestamp}\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üíæ SAVING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save final model\n",
    "if history.parameters:\n",
    "    final_parameters = fl.common.parameters_to_ndarrays(history.parameters)\n",
    "    final_model = create_model()\n",
    "    params_dict = zip(final_model.state_dict().keys(), final_parameters)\n",
    "    state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
    "    final_model.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "    model_path = os.path.join(results_dir, 'final_model.pth')\n",
    "    torch.save(final_model.state_dict(), model_path)\n",
    "    print(f\"‚úÖ Model saved: {model_path}\")\n",
    "\n",
    "# Save training history\n",
    "history_dict = {\n",
    "    'losses_distributed': history.losses_distributed,\n",
    "    'losses_centralized': history.losses_centralized,\n",
    "    'metrics_distributed': history.metrics_distributed,\n",
    "    'metrics_centralized': history.metrics_centralized,\n",
    "}\n",
    "\n",
    "history_path = os.path.join(results_dir, 'training_history.pkl')\n",
    "with open(history_path, 'wb') as f:\n",
    "    pickle.dump(history_dict, f)\n",
    "print(f\"‚úÖ History saved: {history_path}\")\n",
    "\n",
    "# Save configuration\n",
    "config_path = os.path.join(results_dir, 'config.txt')\n",
    "with open(config_path, 'w') as f:\n",
    "    f.write(f\"Federated Learning Configuration\\n\")\n",
    "    f.write(f\"=\" * 50 + \"\\n\")\n",
    "    f.write(f\"Number of Rounds: {Config.NUM_ROUNDS}\\n\")\n",
    "    f.write(f\"Number of Clients: {Config.NUM_CLIENTS}\\n\")\n",
    "    f.write(f\"Local Epochs: {Config.LOCAL_EPOCHS}\\n\")\n",
    "    f.write(f\"Batch Size: {Config.BATCH_SIZE}\\n\")\n",
    "    f.write(f\"Learning Rate: {Config.LEARNING_RATE}\\n\")\n",
    "    f.write(f\"Device: {Config.DEVICE}\\n\")\n",
    "\n",
    "print(f\"‚úÖ Config saved: {config_path}\")\n",
    "print(f\"\\nüìÅ All results saved to: {results_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b38ee189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä TRAINING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üéØ Global Model Performance:\n",
      "----------------------------------------------------------------------\n",
      "Round  1: Loss=0.4850, Accuracy=81.38%\n",
      "\n",
      "======================================================================\n",
      "üèÜ FINAL RESULTS:\n",
      "   ‚Ä¢ Final Accuracy: 81.38%\n",
      "   ‚Ä¢ Final Loss: 0.4850\n",
      "   ‚Ä¢ Initial Accuracy: 81.38%\n",
      "   ‚Ä¢ Improvement: +0.00%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 15: Display Training Summary\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä TRAINING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if history.losses_centralized:\n",
    "    print(\"\\nüéØ Global Model Performance:\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for round_num, (loss, metrics) in enumerate(\n",
    "        zip(history.losses_centralized, history.metrics_centralized), start=1\n",
    "    ):\n",
    "        acc = metrics.get('accuracy', 0)\n",
    "        print(f\"Round {round_num:2d}: Loss={loss:.4f}, Accuracy={acc:.2f}%\")\n",
    "    \n",
    "    # Final metrics\n",
    "    final_loss = history.losses_centralized[-1]\n",
    "    final_acc = history.metrics_centralized[-1].get('accuracy', 0)\n",
    "    initial_acc = history.metrics_centralized[0].get('accuracy', 0)\n",
    "    improvement = final_acc - initial_acc\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"üèÜ FINAL RESULTS:\")\n",
    "    print(f\"   ‚Ä¢ Final Accuracy: {final_acc:.2f}%\")\n",
    "    print(f\"   ‚Ä¢ Final Loss: {final_loss:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Initial Accuracy: {initial_acc:.2f}%\")\n",
    "    print(f\"   ‚Ä¢ Improvement: +{improvement:.2f}%\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a07b6d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Creating visualizations...\n",
      "‚úÖ Plot saved: ./results/fl_training_20251030_210659\\training_metrics.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 16: Visualize Training Results\n",
    "\n",
    "print(\"\\nüìä Creating visualizations...\")\n",
    "\n",
    "# Extract metrics\n",
    "rounds = list(range(1, len(history.metrics_centralized) + 1))\n",
    "accuracies = [m.get('accuracy', 0) for m in history.metrics_centralized]\n",
    "losses = history.losses_centralized\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot accuracy\n",
    "ax1.plot(rounds, accuracies, 'b-o', linewidth=2, markersize=8)\n",
    "ax1.set_xlabel('Communication Round', fontsize=14)\n",
    "ax1.set_ylabel('Accuracy (%)', fontsize=14)\n",
    "ax1.set_title('Global Model Accuracy Over Rounds', fontsize=16, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0, 100])\n",
    "\n",
    "# Add accuracy annotations\n",
    "for i in range(0, len(rounds), max(1, len(rounds)//5)):\n",
    "    ax1.annotate(f'{accuracies[i]:.1f}%',\n",
    "                xy=(rounds[i], accuracies[i]),\n",
    "                xytext=(0, 10),\n",
    "                textcoords='offset points',\n",
    "                ha='center',\n",
    "                fontsize=10)\n",
    "\n",
    "# Plot loss\n",
    "ax2.plot(rounds, losses, 'r-o', linewidth=2, markersize=8)\n",
    "ax2.set_xlabel('Communication Round', fontsize=14)\n",
    "ax2.set_ylabel('Loss', fontsize=14)\n",
    "ax2.set_title('Global Model Loss Over Rounds', fontsize=16, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "plot_path = os.path.join(results_dir, 'training_metrics.png')\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"‚úÖ Plot saved: {plot_path}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "609ae357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üìä DETAILED STATISTICS\n",
      "======================================================================\n",
      "\n",
      "üéØ Accuracy Statistics:\n",
      "   ‚Ä¢ Initial: 81.38%\n",
      "   ‚Ä¢ Final: 81.38%\n",
      "   ‚Ä¢ Maximum: 81.38%\n",
      "   ‚Ä¢ Minimum: 81.38%\n",
      "   ‚Ä¢ Mean: 81.38%\n",
      "   ‚Ä¢ Std Dev: 0.00%\n",
      "   ‚Ä¢ Improvement: +0.00%\n",
      "\n",
      "üìâ Loss Statistics:\n",
      "   ‚Ä¢ Initial: 0.4850\n",
      "   ‚Ä¢ Final: 0.4850\n",
      "   ‚Ä¢ Maximum: 0.4850\n",
      "   ‚Ä¢ Minimum: 0.4850\n",
      "   ‚Ä¢ Mean: 0.4850\n",
      "   ‚Ä¢ Std Dev: 0.0000\n",
      "   ‚Ä¢ Reduction: -0.0000\n",
      "\n",
      "‚è±Ô∏è  Training Info:\n",
      "   ‚Ä¢ Total Rounds: 1\n",
      "   ‚Ä¢ Clients: 1\n",
      "   ‚Ä¢ Local Epochs per Round: 10\n",
      "   ‚Ä¢ Total Local Epochs: 10\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 17: Detailed Statistics\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä DETAILED STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüéØ Accuracy Statistics:\")\n",
    "print(f\"   ‚Ä¢ Initial: {accuracies[0]:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Final: {accuracies[-1]:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Maximum: {max(accuracies):.2f}%\")\n",
    "print(f\"   ‚Ä¢ Minimum: {min(accuracies):.2f}%\")\n",
    "print(f\"   ‚Ä¢ Mean: {np.mean(accuracies):.2f}%\")\n",
    "print(f\"   ‚Ä¢ Std Dev: {np.std(accuracies):.2f}%\")\n",
    "print(f\"   ‚Ä¢ Improvement: +{accuracies[-1] - accuracies[0]:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìâ Loss Statistics:\")\n",
    "print(f\"   ‚Ä¢ Initial: {losses[0]:.4f}\")\n",
    "print(f\"   ‚Ä¢ Final: {losses[-1]:.4f}\")\n",
    "print(f\"   ‚Ä¢ Maximum: {max(losses):.4f}\")\n",
    "print(f\"   ‚Ä¢ Minimum: {min(losses):.4f}\")\n",
    "print(f\"   ‚Ä¢ Mean: {np.mean(losses):.4f}\")\n",
    "print(f\"   ‚Ä¢ Std Dev: {np.std(losses):.4f}\")\n",
    "print(f\"   ‚Ä¢ Reduction: -{losses[0] - losses[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è  Training Info:\")\n",
    "print(f\"   ‚Ä¢ Total Rounds: {Config.NUM_ROUNDS}\")\n",
    "print(f\"   ‚Ä¢ Clients: {Config.NUM_CLIENTS}\")\n",
    "print(f\"   ‚Ä¢ Local Epochs per Round: {Config.LOCAL_EPOCHS}\")\n",
    "print(f\"   ‚Ä¢ Total Local Epochs: {Config.NUM_ROUNDS * Config.NUM_CLIENTS * Config.LOCAL_EPOCHS}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f87bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18: Final Summary and Next Steps\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ú® TRAINING COMPLETE - NEXT STEPS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üéâ Congratulations! Your federated learning training is complete!\n",
    "\n",
    "üìÅ Results saved in: {results_dir}\n",
    "\n",
    "üìä Files created:\n",
    "   ‚Ä¢ final_model.pth - Trained model weights\n",
    "   ‚Ä¢ training_history.pkl - Complete training history\n",
    "   ‚Ä¢ config.txt - Training configuration\n",
    "   ‚Ä¢ training_metrics.png - Accuracy and loss plots\n",
    "\n",
    "üèÜ Final Performance:\n",
    "   ‚Ä¢ Test Accuracy: {accuracies[-1]:.2f}%\n",
    "   ‚Ä¢ Test Loss: {losses[-1]:.4f}\n",
    "\n",
    "üî¨ What you can do next:\n",
    "   1. Test the model on new images\n",
    "   2. Implement model poisoning attacks\n",
    "   3. Add anomaly detection algorithms\n",
    "   4. Compare with centralized training\n",
    "   5. Generate confusion matrix\n",
    "   6. Calculate per-class metrics\n",
    "\n",
    "üí° To add attacks and detection:\n",
    "   - Modify client training in Cell 9\n",
    "   - Add attack functions\n",
    "   - Implement Isolation Forest/One-Class SVM detection\n",
    "   - Compare clean vs attacked performance\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"‚úÖ All done! Ready for next phase: Attacks & Detection\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resNet18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
